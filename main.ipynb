{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:12.116 - INFO : Initializing logger.. complete!\n"
     ]
    }
   ],
   "source": [
    "# Import data and main configurations\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s.%(msecs)03d - %(levelname)s : %(message)s',\n",
    "        datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info('Initializing logger.. complete!')\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sample = False, n = 1000):\n",
    "    \"\"\"\n",
    "    Loads the wine dataset\n",
    "    It can be the full dataset or just a sample\n",
    "    \"\"\"\n",
    "    \n",
    "    path = 'data/winemag-data-130k-v2.csv'\n",
    "\n",
    "    df = pd.read_csv(path).drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    if sample:\n",
    "        df = df[:n]\n",
    "\n",
    "    logger.info(f'File uploaded with {df.shape[0]} rows and {df.shape[1]} columns')\n",
    "\n",
    "    numerical_columns = df.select_dtypes(include = np.number).columns\n",
    "    categorical_columns = df.columns.drop(numerical_columns)\n",
    "    target = 'variety'\n",
    "\n",
    "    logger.info(f'Numerical columns: {numerical_columns}')\n",
    "    logger.info(f'Categorical columns: {categorical_columns}')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_columns(df, cols, option = 'alphanumeric'):\n",
    "    \"\"\"\n",
    "    Cleans text columns including lowering and regex\n",
    "    with the following options:\n",
    "    \n",
    "    alphanumeric - keeps letters, numbers and white spaces.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if option == 'alphanumeric':\n",
    "        regex = r'([^A-Za-z0-9 ]+)'\n",
    "\n",
    "    \n",
    "    logger.info('Cleaning {cols}...')\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.replace(regex, '').str.lower()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df, cols):\n",
    "    \n",
    "    init = df.shape[0]  \n",
    "    logger.info(f'Droping columns {cols}')\n",
    "    \n",
    "    df = df.drop(cols, axis=1)\n",
    "    \n",
    "    end = df.shape[0]\n",
    "    logger.info(f'Dataframe columns reduced: {init} -> {end}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of classes to consider\n",
    "\n",
    "def select_top_classes(df, target_col = 'target', n=40):\n",
    "    top_varieties = n\n",
    "    initial_rows = df.shape[0]\n",
    "\n",
    "    top_classes = (df.target.value_counts().sort_values(ascending=False).head(top_varieties)).index\n",
    "    df = df[df['target'].isin(top_classes)]\n",
    "\n",
    "    logger.info(f'Reducing the dataset to highest {top_varieties} classes.')\n",
    "    logger.info(f'Dataframe reduced from {initial_rows} rows to {df.shape[0]}.')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_missing_values(df, null_col, info_col):\n",
    "    \n",
    "    null_values_init = df[df[null_col].isnull()].shape[0]\n",
    "\n",
    "    logger.info(f'Creating a map of {null_col} -> {info_col} and apply to the null values...')\n",
    "\n",
    "    prop_map = df[[null_col, info_col]].sort_values(info_col, ascending=True, na_position='last').groupby(info_col)[null_col].first()\n",
    "    df[null_col] = df[info_col].map(prop_map)\n",
    "\n",
    "\n",
    "    null_values_final = df[df[null_col].isnull()].shape[0]\n",
    "    logger.info(f'Map succeccefully applied! Went from {null_values_init} missing {null_col} to {null_values_final}.')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_nulls_from_col(df, null_col, info_col):\n",
    "   \n",
    "    logger.info(f'Copy vaalues from {info_col} to {null_col}')\n",
    "\n",
    "    nulls = df[df[null_col].isnull()].shape[0]\n",
    "    df.loc[df[null_col].isnull(), null_col] = df[info_col]\n",
    "    \n",
    "    logger.info(f'Finished! {nulls} values were copied.')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nulls_to_unknown(df, col, value = 'unknown'):\n",
    "    \n",
    "    logger.info(f'Converting null values to {value}..')\n",
    "\n",
    "    df.loc[df.col.isnull(), col] = value\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_buckets(df, bin_col = 'points', new_col = 'bucket', n_bins = 8):\n",
    "    \n",
    "    logger.info(f'Bucketing column {bin_col} in {n_bins} buckets to column {new_col}')\n",
    "    \n",
    "    df[new_col] = pd.qcut(df[bin_col], n_bins, labels=range(n_bins))\n",
    "    \n",
    "#     df[new_col] = df[new_col].astype('Int64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_null_location_in_google(df, option = 'country', null_col = 'country', info_col = 'winery'):\n",
    "    \"\"\"\n",
    "    This function utilizes the scaleserp API to query Google Knowledge Graphs\n",
    "    \n",
    "    Takes as input:\n",
    "    \n",
    "    null_col: the column with the null values\n",
    "    info_col: the col to query google KG\n",
    "    option: the location option we want to retrieve\n",
    "    \n",
    "    \n",
    "    Obs: uncomment following 'complete' line to get the complete \n",
    "    list of missing values and comment the 'example' one\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    init = df[null_col].isnull().sum()\n",
    "    logger.info(f'Finding {option} by query Google Knowledge Graphs for {info_col}. There are {init} values missing.')\n",
    "        \n",
    "    # complete\n",
    "    # info_values = df[df[null_col].isnull()][info_col].unique()  \n",
    "    \n",
    "    # example\n",
    "    info_values = ['Gotsa Family Wines', 'Barton & Guestier','Kakhetia Traditional Winemaking', 'Tsililis']           \n",
    "    \n",
    "    loc_map = {}\n",
    "\n",
    "    for value in info_values:\n",
    "\n",
    "        params = {\n",
    "          'api_key': '802701F0BC0E4726914B6982E70A541A',\n",
    "          'q': f'{value} {info_col}'\n",
    "        }\n",
    "\n",
    "        api_result = requests.get('https://api.scaleserp.com/search', params).json()\n",
    "\n",
    "        try:\n",
    "\n",
    "            local_map = api_result['knowledge_graph']['local_map']\n",
    "            lat = local_map['gps_coordinates']['latitude']\n",
    "            long = local_map['gps_coordinates']['longitude']\n",
    "\n",
    "            geolocator = Nominatim(user_agent=\"app\")\n",
    "            location = geolocator.reverse(f\"{lat},{long}\", language = 'en')\n",
    "            result = location.raw['address'][option]\n",
    "\n",
    "            loc_map[value] = result\n",
    "\n",
    "            print(f'{value}: {result}')\n",
    "\n",
    "\n",
    "        except:\n",
    "            print(f'{value}: {option} not found')\n",
    "            pass\n",
    "\n",
    "    logger.info(f'Applying map of fetched `{null_col}`...')   \n",
    "\n",
    "    df.loc[df[null_col].isnull(), null_col] = df[info_col].map(loc_map)\n",
    "    \n",
    "    \n",
    "    end = df[null_col].isnull().sum()\n",
    "    logger.info(f'Map aplied. Null values went from {init} to {end}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_seq_from_text_column(df, new_col, col, seq_len = 4):\n",
    "    \n",
    "    regex = str('\\d'*seq_len)\n",
    "    regex = f'({regex})'\n",
    "    \n",
    "    logger.info(f'Finding a sequence of {seq_len}  numbers {regex}in column {col}')    \n",
    "    df[new_col] = df[col].str.extract(regex, expand=False) \n",
    "    \n",
    "#     df[new_col] = df[col].astype('Int64')\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_with_treshold(df, col, threshold = 10):\n",
    "    \"\"\"\n",
    "    1 Standard Deviation from the Mean: 68%\n",
    "    2 Standard Deviations from the Mean: 95%\n",
    "    3 Standard Deviations from the Mean: 99.7%\n",
    "    \n",
    "    \"\"\"\n",
    "    logger.info(f'Removing outliers from column {col} out of {threshold} std dev.')\n",
    "   \n",
    "    init = df.shape[0]\n",
    "    \n",
    "    data_mean = np.mean(df[col])\n",
    "    data_std = np.std(df[col])\n",
    "    cut_off = data_std * threshold\n",
    "    upper = data_mean + cut_off\n",
    "    lower = data_mean - cut_off\n",
    "    lower = lower if lower>0 else 0\n",
    "    \n",
    "    df = df[(df[col] > lower) & (df[col] < upper)]\n",
    "    \n",
    "    end = df.shape[0]\n",
    "    \n",
    "    logger.info(f'Dataframe rows reduced {init} -> {end}')\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values_stat_impute(df, null_col, info_col, mode = np.median):\n",
    "    \"\"\"\n",
    "    Impute the null values with the \n",
    "    median/mean of a column\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f'Imputing the {mode} of column {info_col} into null values of {null_col}')\n",
    "    mapper = df.groupby(info_col).median()[null_col]\n",
    "    df.loc[df[null_col].isnull(),null_col] = df[info_col].map(mapper)\n",
    "    df[null_col] = df[null_col].astype('float64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls_with_median(df, null_col, info_col):\n",
    "    \n",
    "    \n",
    "    logger.info(f'Imputing the median of column {info_col} into null values of {null_col}')\n",
    "\n",
    "    mapper = df.groupby(info_col).median()[null_col]\n",
    "    df.loc[df[null_col].isnull(),null_col] = df[info_col].map(mapper)\n",
    "    df[null_col] = df[null_col].astype('float64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grape_names(df, col):\n",
    "    \n",
    "    logger.info(f'Correcting grapes names and matching foreign names...')\n",
    "    def _correct_name(row):\n",
    "        regexp = [r'shiraz', r'ugni blanc', r'cinsaut', r'carinyena', r'^ribolla$', r'palomino', r'turbiana', r'verdelho', r'viura', r'pinot bianco|weissburgunder', r'garganega|grecanico', r'moscatel', r'moscato', r'melon de bourgogne', r'trajadura|trincadeira', r'cannonau|garnacha', r'grauburgunder|pinot grigio', r'pinot noir|pinot nero', r'colorino', r'mataro|monastrell', r'mourv(\\w+)']\n",
    "        grapename = ['syrah', 'trebbiano', 'cinsault', 'carignan', 'ribolla gialla', 'palomino','verdicchio', 'verdejo','macabeo', 'pinot blanc', 'garganega', 'muscatel', 'muscat', 'muscadet', 'treixadura', 'grenache', 'pinot gris', 'pinot noir', 'lambrusco', 'mourvedre', 'mourvedre']\n",
    "        f = row\n",
    "        for exsearch, gname in zip(regexp, grapename):\n",
    "            f = re.sub(exsearch, gname, f)\n",
    "        return f\n",
    "\n",
    "\n",
    "    name_pairs = [('spatburgunder', 'pinot noir'), ('garnacha', 'grenache'), ('pinot nero', 'pinot noir'),\n",
    "                  ('alvarinho', 'albarino'), ('assyrtico', 'assyrtiko'), ('black muscat', 'muscat hamburg'),\n",
    "                  ('kekfrankos', 'blaufrankisch'), ('garnacha blanca', 'grenache blanc'),\n",
    "                  ('garnacha tintorera', 'alicante bouschet'), ('sangiovese grosso', 'sangiovese')\n",
    "                 ]\n",
    "    \n",
    "    df[col] = df[col].apply(lambda row: _correct_name(row))\n",
    "    \n",
    "    for wrong, right in name_pairs:\n",
    "        df[col] = df[col].replace(wrong, right) \n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratio(df, col1, col2, col_name):\n",
    "    \"\"\"\n",
    "    Creates a new column with the ratio of 2\n",
    "    given numerical columns.\n",
    "    \"\"\"\n",
    "        \n",
    "    df.loc[(~df[col1].isnull()) & (~df[col2].isnull()), col_name] = round(df[col1]/df[col2],2)\n",
    "    \n",
    "    logger.info(f'Created ratio feature {col_name} ({col1} / {col2})')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords_list(df, cols, language = 'english', extra_words = []):\n",
    "    \"\"\"\n",
    "    Creates a list with the stopwords of input language\n",
    "    and additionally the categories of given columns.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info('Creating a list for stopwords..')\n",
    "    \n",
    "    extra_words = ['.', ',', '`', '\"', \"'\", '!', ';', 'wine', 'fruit', '%', 'flavour', 'aromas', 'palate']\n",
    "    stop_words = stopwords.words(language)\n",
    "    \n",
    "    for col in cols:\n",
    "        stop_words.append(df[col].unique())\n",
    "    \n",
    "    \n",
    "    stop_words = stop_words + extra_words\n",
    "    \n",
    "    return stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_small_text_column(df, col, stop_words, regex = '[^a-zA-Z]', wanted_tags = []):\n",
    "    \"\"\"\n",
    "    Function to process small text columns, like descriptions.\n",
    "    Processing includes:\n",
    "    \n",
    "    1. Parse with the input regex and lowercase\n",
    "    2. Remove stopwords from input language and from input categorical columns\n",
    "    3. Keep only words with input (grammar) tags\n",
    "    4. Convert each word to its lemma\n",
    "    5. Convert list of tokens back to string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f'Processing text column {col}...')\n",
    "    \n",
    "    wanted_tags = ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJS', 'JJR', 'VBN', 'VBP']\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "    extra_words = ['.', ',', '`', '\"', \"'\", '!', ';', 'wine', 'fruit', '%', 'flavour', 'aromas', 'palate']\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words = stop_words + extra_words + list(df.columns)\n",
    "\n",
    "    def _process_text(text):\n",
    "        tokens = word_tokenize(re.sub(regex, ' ',text).lower())\n",
    "        tokens = [token for token in tokens if not token in stop_words]\n",
    "        text = nltk.pos_tag(tokens)\n",
    "        text = [lemmatizer.lemmatize(token[0]) for token in text if token[1] in wanted_tags]\n",
    "        text = ' '.join(text)\n",
    "        return text\n",
    "    \n",
    "    df[col] = df[col].apply(lambda x: _process_text(x))\n",
    "    \n",
    "    logger.info('Finished processing!')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_cloud(df, col, top_n_words = 30):\n",
    "    \n",
    "    logger.info(f'Vectorizing `{col}` feature to Word Cloud..')\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,3), \n",
    "                                 max_features=500)\n",
    "    \n",
    "    X = vectorizer.fit_transform(df[col])\n",
    "    matrix = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n",
    "    matrix.index = df.index\n",
    "    matrix.head()\n",
    "\n",
    "\n",
    "    logger.info(f'Generating wordcloud...')\n",
    "    \n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='black',\n",
    "        max_words=top_n_words,\n",
    "        max_font_size=40, \n",
    "        scale=5,\n",
    "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
    "    ).generate(str(matrix))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "    logger.info(f'Done!')\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_sentiment_from_text_col(df, col):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f'Calculating sentiment polarity and subjectivity of `{col}`...')\n",
    "\n",
    "    df['sentiment_pol']= df[col].apply(lambda x: float(round(TextBlob(x).sentiment.polarity, 2)))\n",
    "    df['sentiment_sub']= df[col].apply(lambda x: float(round(TextBlob(x).sentiment.subjectivity, 2)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_matrix_of_col(df, col, max_features=500, ngrams_range=(1,3)):\n",
    "    \"\"\"\n",
    "    Takes a text column and returns a vector matrix\n",
    "    with the most frequent terms.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f'Vectorizing `{col}` feature with TFIDF...')\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngrams_range, \n",
    "                                 max_df = 0.25, \n",
    "                                 min_df = 0.005, \n",
    "                                 max_features=max_features,\n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True) \n",
    "\n",
    "    X = vectorizer.fit_transform(df[col])\n",
    "    \n",
    "    matrix = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n",
    "    matrix.index = df.index\n",
    "    \n",
    "    for col in matrix.columns:\n",
    "        col = '_'.join(col)\n",
    "    \n",
    "    logger.info(f'Finish! Created sparse matrix with shape {matrix.shape}')\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_multiclass(X,y): #\n",
    "    \"\"\"\n",
    "    X,y are pandas df and series\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f'Target encoding categorical features...')\n",
    "    y=y.astype(str)   #convert to string to onehot encode\n",
    "    enc=ce.OneHotEncoder().fit(y)\n",
    "    y_onehot=enc.transform(y)\n",
    "    class_names=y_onehot.columns  #names of onehot encoded columns\n",
    "    \n",
    "    X_obj=X.select_dtypes('object') #separate categorical columns\n",
    "    X=X.select_dtypes(exclude='object') \n",
    "    for class_ in class_names:\n",
    "      \n",
    "        enc=ce.TargetEncoder()\n",
    "        enc.fit(X_obj,y_onehot[class_]) #convert all categorical \n",
    "        temp=enc.transform(X_obj)       #columns for class_\n",
    "        temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "        X=pd.concat([X,temp],axis=1)    #add to original dataset\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(preds, target, labels, sep='-', sep_len=80, fig_size=(10,8)):\n",
    "    print('Accuracy = %.3f' % metrics.accuracy_score(target, preds))\n",
    "    print(sep*sep_len)\n",
    "#     print('Classification report:')\n",
    "#     print(metrics.classification_report(target, preds))\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:15.966 - INFO : File uploaded with 129971 rows and 13 columns\n",
      "12:35:15.970 - INFO : Numerical columns: Index(['points', 'price'], dtype='object')\n",
      "12:35:15.971 - INFO : Categorical columns: Index(['country', 'description', 'designation', 'province', 'region_1',\n",
      "       'region_2', 'taster_name', 'taster_twitter_handle', 'title', 'variety',\n",
      "       'winery'],\n",
      "      dtype='object')\n",
      "12:35:16.025 - INFO : Reducing the dataset to highest 40 classes.\n",
      "12:35:16.026 - INFO : Dataframe reduced from 129971 rows to 111797.\n",
      "12:35:16.036 - INFO : Creating a map of country -> winery and apply to the null values...\n",
      "12:35:16.170 - INFO : Map succeccefully applied! Went from 40 missing country to 23.\n",
      "12:35:16.175 - INFO : Creating a map of province -> winery and apply to the null values...\n",
      "12:35:16.308 - INFO : Map succeccefully applied! Went from 40 missing province to 23.\n",
      "12:35:16.309 - INFO : Copy vaalues from province to region_1\n",
      "12:35:16.328 - INFO : Finished! 17681 values were copied.\n",
      "12:35:16.328 - INFO : Bucketing column points in 8 buckets to column points_bucket\n",
      "12:35:16.334 - INFO : Bucketing column price in 8 buckets to column price_bucket\n",
      "12:35:16.343 - INFO : Finding a sequence of 4  numbers (\\d\\d\\d\\d)in column title\n",
      "12:35:16.463 - INFO : Correcting grapes names and matching foreign names...\n",
      "12:35:18.358 - INFO : Created ratio feature quality_price_ratio (points / price)\n",
      "12:35:18.359 - INFO : Calculating sentiment polarity and subjectivity of `description`...\n"
     ]
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "df = load_data(sample = False, n = 10000)\n",
    "df = df.rename(columns={'variety': 'target'})\n",
    "df = select_top_classes(df, 'target', 40)\n",
    "df = propagate_missing_values(df, 'country', 'winery')\n",
    "df = propagate_missing_values(df, 'province', 'winery')\n",
    "df = copy_nulls_from_col(df, 'region_1', 'province')\n",
    "# df = find_null_location_in_google(df, option = 'country', null_col = 'country', info_col = 'winery')\n",
    "# df = convert_nulls_to_unknown(df, col, value = unknown)\n",
    "# df = remove_outliers_with_treshold(df, price, threshold = 10)\n",
    "\n",
    "#Feature Engineering\n",
    "df = analyse_sentiment_from_text_col(df, 'description')\n",
    "df = generate_buckets(df, bin_col = 'points' , new_col = 'points_bucket', n_bins = 8)\n",
    "df = generate_buckets(df, bin_col = 'price', new_col = 'price_bucket', n_bins = 8)\n",
    "df = get_number_seq_from_text_column(df, 'year' , 'title', seq_len = 4)\n",
    "# df = null_values_stat_impute(df, price, points_bucked, mode = np.median)\n",
    "df = correct_grape_names(df, 'target')\n",
    "\n",
    "# new features\n",
    "df = create_ratio(df, col1 = 'points', col2 = 'price', col_name = 'quality_price_ratio')\n",
    "df.to_csv('silver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description processing\n",
    "df = clean_text_columns(df, ['target', 'winery', 'taster_name', 'region_1', 'province'])\n",
    "stop_words = get_stopwords_list(df, cols = ['country', 'province', 'winery'], language = 'english', extra_words = [])\n",
    "df = process_small_text_column(df, 'description', stop_words = stop_words)\n",
    "matrix = get_tfidf_matrix_of_col(df, 'description', max_features=500)\n",
    "df = pd.concat([df, matrix], axis=1)\n",
    "# generate_word_cloud(df, 'target', top_n_words = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:27.916 - INFO : Cleaning {cols}...\n",
      "12:36:28.490 - INFO : Creating a list for stopwords..\n",
      "12:36:28.526 - INFO : Processing text column description...\n",
      "12:39:31.422 - INFO : Finished processing!\n",
      "12:39:31.423 - INFO : Vectorizing `description` feature with TFIDF...\n",
      "12:39:43.628 - INFO : Finish! Created sparse matrix with shape (111797, 500)\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('gold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gold.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# deal with nulls, encodings, norms\n",
    "df = df.drop(['description', 'designation', 'region_2', 'taster_twitter_handle', 'title', 'province', 'region_1', 'winery'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# le_cols = ['target']\n",
    "# ohe_cols = df[['country', 'taster_name']]\n",
    "\n",
    "# ohe_predictors = pd.get_dummies(ohe_cols)\n",
    "# df = pd.concat([df, ohe_predictors], axis=1).drop(['country', 'taster_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>target</th>\n",
       "      <th>points_bucket</th>\n",
       "      <th>price_bucket</th>\n",
       "      <th>year</th>\n",
       "      <th>quality_price_ratio</th>\n",
       "      <th>sentiment_pol</th>\n",
       "      <th>...</th>\n",
       "      <th>wine</th>\n",
       "      <th>winemaker</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>year.1</th>\n",
       "      <th>yellow</th>\n",
       "      <th>young</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zinfandel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kerin okeefe</td>\n",
       "      <td>white blend</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>roger voss</td>\n",
       "      <td>portuguese red</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>paul gregutt</td>\n",
       "      <td>pinot gris</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>6.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>alexander peartree</td>\n",
       "      <td>riesling</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>paul gregutt</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111792</th>\n",
       "      <td>Germany</td>\n",
       "      <td>90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>anna lee c iijima</td>\n",
       "      <td>riesling</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111793</th>\n",
       "      <td>US</td>\n",
       "      <td>90</td>\n",
       "      <td>75.0</td>\n",
       "      <td>paul gregutt</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111794</th>\n",
       "      <td>France</td>\n",
       "      <td>90</td>\n",
       "      <td>30.0</td>\n",
       "      <td>roger voss</td>\n",
       "      <td>gewrztraminer</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111795</th>\n",
       "      <td>France</td>\n",
       "      <td>90</td>\n",
       "      <td>32.0</td>\n",
       "      <td>roger voss</td>\n",
       "      <td>pinot gris</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111796</th>\n",
       "      <td>France</td>\n",
       "      <td>90</td>\n",
       "      <td>21.0</td>\n",
       "      <td>roger voss</td>\n",
       "      <td>gewrztraminer</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111797 rows Ã— 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  points  price         taster_name          target  \\\n",
       "0          Italy      87    NaN        kerin okeefe     white blend   \n",
       "1       Portugal      87   15.0          roger voss  portuguese red   \n",
       "2             US      87   14.0        paul gregutt      pinot gris   \n",
       "3             US      87   13.0  alexander peartree        riesling   \n",
       "4             US      87   65.0        paul gregutt      pinot noir   \n",
       "...          ...     ...    ...                 ...             ...   \n",
       "111792   Germany      90   28.0   anna lee c iijima        riesling   \n",
       "111793        US      90   75.0        paul gregutt      pinot noir   \n",
       "111794    France      90   30.0          roger voss   gewrztraminer   \n",
       "111795    France      90   32.0          roger voss      pinot gris   \n",
       "111796    France      90   21.0          roger voss   gewrztraminer   \n",
       "\n",
       "        points_bucket  price_bucket    year  quality_price_ratio  \\\n",
       "0                   2           NaN  2013.0                  NaN   \n",
       "1                   2           1.0  2011.0                 5.80   \n",
       "2                   2           1.0  2013.0                 6.21   \n",
       "3                   2           0.0  2013.0                 6.69   \n",
       "4                   2           7.0  2012.0                 1.34   \n",
       "...               ...           ...     ...                  ...   \n",
       "111792              4           4.0  2013.0                 3.21   \n",
       "111793              4           7.0  2004.0                 1.20   \n",
       "111794              4           4.0  2013.0                 3.00   \n",
       "111795              4           4.0  2012.0                 2.81   \n",
       "111796              4           2.0  2012.0                 4.29   \n",
       "\n",
       "        sentiment_pol  ...  wine  winemaker  wood  woody    year.1  yellow  \\\n",
       "0                0.13  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "1                0.22  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "2                0.02  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "3                0.17  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "4                0.31  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "...               ...  ...   ...        ...   ...    ...       ...     ...   \n",
       "111792           0.60  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "111793           0.00  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "111794           0.09  ...   0.0        0.0   0.0    0.0  0.281992     0.0   \n",
       "111795           0.12  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "111796           0.19  ...   0.0        0.0   0.0    0.0  0.000000     0.0   \n",
       "\n",
       "        young  zest  zesty  zinfandel  \n",
       "0         0.0   0.0    0.0        0.0  \n",
       "1         0.0   0.0    0.0        0.0  \n",
       "2         0.0   0.0    0.0        0.0  \n",
       "3         0.0   0.0    0.0        0.0  \n",
       "4         0.0   0.0    0.0        0.0  \n",
       "...       ...   ...    ...        ...  \n",
       "111792    0.0   0.0    0.0        0.0  \n",
       "111793    0.0   0.0    0.0        0.0  \n",
       "111794    0.0   0.0    0.0        0.0  \n",
       "111795    0.0   0.0    0.0        0.0  \n",
       "111796    0.0   0.0    0.0        0.0  \n",
       "\n",
       "[111797 rows x 511 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[numerical_columns] = pd.to_numeric(df[numerical_columns])\n",
    "\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = le.fit_transform(df['target'])\n",
    "\n",
    "\n",
    "categorical_columns = ['country', 'taster_name']\n",
    "numerical_columns = [col for col in X.columns if col not in categorical_columns]\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class_weight = dict(Counter(y))\n",
    "\n",
    "\n",
    "for col in numerical_columns:\n",
    "    X[col] = X[col].astype('float64')\n",
    "\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "# for col in numerical_columns:\n",
    "#     X[col] = preprocessing.scale(X[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89437, 510)\n"
     ]
    }
   ],
   "source": [
    "# Define train, valid and test datasets\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, random_state=42) #, stratify=y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#                                                     test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "#                                                   test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(X_train.shape)\n",
    "# del df; \n",
    "# gc.collect();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "# https://www.kaggle.com/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "# Use an optimizer instead of grid search\n",
    "\n",
    "params = {\n",
    "         'n_estimators': [400],\n",
    "         'num_leaves': [20,50], \n",
    "         'metric': ['multi_error'],\n",
    "         'num_class': [df.target.nunique],\n",
    "         'boosting_type':  ['gbdt'], #otimized to gbdt\n",
    "         'learning_rate': [0.03], # otimized to o.03\n",
    "         'max_depth': [20,30,40], #reduces overfitting\n",
    "         'bagging_fraction': [0.6], # speeds up training and reduces overfit. otimized to 0.6\n",
    "         'feature_fraction': [0.7], # speeds up training and reduces overfit, otimized to 0.7\n",
    "         'lambda_l1': [0, 0.1],\n",
    "         'lambda_l2': [0, 0.1]\n",
    "         \n",
    "        }\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "\n",
    "#         nfold = 3, \n",
    "#         stratified=True,\n",
    "        seed = 42,\n",
    "        objective = 'multiclass',\n",
    "        is_unbalance = True,\n",
    "        metric = 'multi_error'\n",
    "\n",
    "        \n",
    "#         class_weight = class_weight # this decreases the accuracy a lot... weird\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(lgbm, params, n_jobs=-1, verbose=1, cv = 2, return_train_score=True) # refit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 200.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 38min 20s, sys: 1min 37s, total: 1h 39min 58s\n",
      "Wall time: 3h 26min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      is_unbalance=True, learning_rate=0.1,\n",
       "                                      max_depth=-1, metric='multi_error',\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31,\n",
       "                                      objective='multiclass', random_sta...\n",
       "                         'n_estimators': [400],\n",
       "                         'num_class': [<bound method IndexOpsMixin.nunique of 0            white blend\n",
       "1         portuguese red\n",
       "2             pinot gris\n",
       "3               riesling\n",
       "4             pinot noir\n",
       "               ...      \n",
       "111792          riesling\n",
       "111793        pinot noir\n",
       "111794     gewrztraminer\n",
       "111795        pinot gris\n",
       "111796     gewrztraminer\n",
       "Name: target, Length: 111797, dtype: object>],\n",
       "                         'num_leaves': [20, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train, verbose = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bagging_fraction</th>\n",
       "      <th>param_boosting_type</th>\n",
       "      <th>param_feature_fraction</th>\n",
       "      <th>param_lambda_l1</th>\n",
       "      <th>param_lambda_l2</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2106.717119</td>\n",
       "      <td>4.607581</td>\n",
       "      <td>460.474902</td>\n",
       "      <td>1.848634</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700552</td>\n",
       "      <td>0.700836</td>\n",
       "      <td>0.700694</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>22</td>\n",
       "      <td>0.864574</td>\n",
       "      <td>0.863615</td>\n",
       "      <td>0.864094</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3522.537009</td>\n",
       "      <td>13.952864</td>\n",
       "      <td>591.010019</td>\n",
       "      <td>1.072611</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.711197</td>\n",
       "      <td>0.709893</td>\n",
       "      <td>0.710545</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>12</td>\n",
       "      <td>0.971242</td>\n",
       "      <td>0.970057</td>\n",
       "      <td>0.970650</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2111.888338</td>\n",
       "      <td>3.980512</td>\n",
       "      <td>461.092896</td>\n",
       "      <td>1.919770</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700552</td>\n",
       "      <td>0.700836</td>\n",
       "      <td>0.700694</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>22</td>\n",
       "      <td>0.864574</td>\n",
       "      <td>0.863615</td>\n",
       "      <td>0.864094</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3898.801051</td>\n",
       "      <td>20.186629</td>\n",
       "      <td>593.120646</td>\n",
       "      <td>2.294687</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.712538</td>\n",
       "      <td>0.710318</td>\n",
       "      <td>0.711428</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>5</td>\n",
       "      <td>0.976408</td>\n",
       "      <td>0.974776</td>\n",
       "      <td>0.975592</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2109.210137</td>\n",
       "      <td>5.787094</td>\n",
       "      <td>459.984924</td>\n",
       "      <td>1.588703</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700552</td>\n",
       "      <td>0.700836</td>\n",
       "      <td>0.700694</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>22</td>\n",
       "      <td>0.864574</td>\n",
       "      <td>0.863615</td>\n",
       "      <td>0.864094</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3994.937822</td>\n",
       "      <td>18.138920</td>\n",
       "      <td>595.878026</td>\n",
       "      <td>2.035827</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.712561</td>\n",
       "      <td>0.710072</td>\n",
       "      <td>0.711316</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>7</td>\n",
       "      <td>0.976676</td>\n",
       "      <td>0.975313</td>\n",
       "      <td>0.975994</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2045.638161</td>\n",
       "      <td>0.535360</td>\n",
       "      <td>454.171454</td>\n",
       "      <td>1.031184</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.701223</td>\n",
       "      <td>0.701776</td>\n",
       "      <td>0.701499</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>13</td>\n",
       "      <td>0.860682</td>\n",
       "      <td>0.859568</td>\n",
       "      <td>0.860125</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3204.138321</td>\n",
       "      <td>26.105205</td>\n",
       "      <td>583.438805</td>\n",
       "      <td>2.107711</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.710906</td>\n",
       "      <td>0.710653</td>\n",
       "      <td>0.710780</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>11</td>\n",
       "      <td>0.968782</td>\n",
       "      <td>0.967665</td>\n",
       "      <td>0.968223</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2079.395310</td>\n",
       "      <td>2.611996</td>\n",
       "      <td>455.744992</td>\n",
       "      <td>2.529174</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.701223</td>\n",
       "      <td>0.701776</td>\n",
       "      <td>0.701499</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>13</td>\n",
       "      <td>0.860682</td>\n",
       "      <td>0.859568</td>\n",
       "      <td>0.860125</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3745.898948</td>\n",
       "      <td>10.940469</td>\n",
       "      <td>604.215117</td>\n",
       "      <td>2.587434</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.711532</td>\n",
       "      <td>0.710944</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>8</td>\n",
       "      <td>0.974440</td>\n",
       "      <td>0.972629</td>\n",
       "      <td>0.973534</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2085.652683</td>\n",
       "      <td>4.246603</td>\n",
       "      <td>460.848863</td>\n",
       "      <td>1.910426</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.701223</td>\n",
       "      <td>0.701776</td>\n",
       "      <td>0.701499</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>13</td>\n",
       "      <td>0.860682</td>\n",
       "      <td>0.859568</td>\n",
       "      <td>0.860125</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3830.501880</td>\n",
       "      <td>15.893937</td>\n",
       "      <td>606.683108</td>\n",
       "      <td>3.475267</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.712270</td>\n",
       "      <td>0.710743</td>\n",
       "      <td>0.711506</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974149</td>\n",
       "      <td>0.972965</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2096.253225</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>433.815838</td>\n",
       "      <td>5.677770</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700888</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.701388</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>16</td>\n",
       "      <td>0.863098</td>\n",
       "      <td>0.861245</td>\n",
       "      <td>0.862171</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3169.368937</td>\n",
       "      <td>14.668849</td>\n",
       "      <td>594.174452</td>\n",
       "      <td>2.735545</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.712225</td>\n",
       "      <td>0.709938</td>\n",
       "      <td>0.711082</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>10</td>\n",
       "      <td>0.970415</td>\n",
       "      <td>0.968403</td>\n",
       "      <td>0.969409</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2140.779276</td>\n",
       "      <td>1.141463</td>\n",
       "      <td>453.459949</td>\n",
       "      <td>2.678942</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700888</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.701388</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>16</td>\n",
       "      <td>0.863098</td>\n",
       "      <td>0.861245</td>\n",
       "      <td>0.862171</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3519.518125</td>\n",
       "      <td>5.917576</td>\n",
       "      <td>597.630370</td>\n",
       "      <td>1.367689</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.712248</td>\n",
       "      <td>0.710542</td>\n",
       "      <td>0.711395</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>6</td>\n",
       "      <td>0.974753</td>\n",
       "      <td>0.973300</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2127.041051</td>\n",
       "      <td>0.837467</td>\n",
       "      <td>448.245053</td>\n",
       "      <td>1.995626</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700888</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.701388</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>16</td>\n",
       "      <td>0.863098</td>\n",
       "      <td>0.861245</td>\n",
       "      <td>0.862171</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3540.382144</td>\n",
       "      <td>4.488180</td>\n",
       "      <td>575.149153</td>\n",
       "      <td>0.853354</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.711800</td>\n",
       "      <td>0.711369</td>\n",
       "      <td>0.711585</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.973747</td>\n",
       "      <td>0.974216</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2085.702826</td>\n",
       "      <td>0.342291</td>\n",
       "      <td>448.762542</td>\n",
       "      <td>1.234084</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700127</td>\n",
       "      <td>0.701552</td>\n",
       "      <td>0.700840</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>19</td>\n",
       "      <td>0.858290</td>\n",
       "      <td>0.857175</td>\n",
       "      <td>0.857732</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2797.111483</td>\n",
       "      <td>3.232854</td>\n",
       "      <td>351.303936</td>\n",
       "      <td>0.091055</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.711085</td>\n",
       "      <td>0.711168</td>\n",
       "      <td>0.711126</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>9</td>\n",
       "      <td>0.967575</td>\n",
       "      <td>0.966368</td>\n",
       "      <td>0.966971</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2027.558751</td>\n",
       "      <td>0.114148</td>\n",
       "      <td>367.692268</td>\n",
       "      <td>1.896880</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700127</td>\n",
       "      <td>0.701552</td>\n",
       "      <td>0.700840</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>19</td>\n",
       "      <td>0.858290</td>\n",
       "      <td>0.857175</td>\n",
       "      <td>0.857732</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2910.646857</td>\n",
       "      <td>5.999643</td>\n",
       "      <td>346.844988</td>\n",
       "      <td>1.177604</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.712538</td>\n",
       "      <td>0.711772</td>\n",
       "      <td>0.712155</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972472</td>\n",
       "      <td>0.971354</td>\n",
       "      <td>0.971913</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1800.047715</td>\n",
       "      <td>2.550900</td>\n",
       "      <td>255.973633</td>\n",
       "      <td>0.882170</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.700127</td>\n",
       "      <td>0.701552</td>\n",
       "      <td>0.700840</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>19</td>\n",
       "      <td>0.858290</td>\n",
       "      <td>0.857175</td>\n",
       "      <td>0.857732</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2477.278483</td>\n",
       "      <td>14.709941</td>\n",
       "      <td>249.095248</td>\n",
       "      <td>2.074602</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>{'bagging_fraction': 0.6, 'boosting_type': 'gb...</td>\n",
       "      <td>0.712762</td>\n",
       "      <td>0.711280</td>\n",
       "      <td>0.712021</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972830</td>\n",
       "      <td>0.971556</td>\n",
       "      <td>0.972193</td>\n",
       "      <td>0.000637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     2106.717119      4.607581       460.474902        1.848634   \n",
       "1     3522.537009     13.952864       591.010019        1.072611   \n",
       "2     2111.888338      3.980512       461.092896        1.919770   \n",
       "3     3898.801051     20.186629       593.120646        2.294687   \n",
       "4     2109.210137      5.787094       459.984924        1.588703   \n",
       "5     3994.937822     18.138920       595.878026        2.035827   \n",
       "6     2045.638161      0.535360       454.171454        1.031184   \n",
       "7     3204.138321     26.105205       583.438805        2.107711   \n",
       "8     2079.395310      2.611996       455.744992        2.529174   \n",
       "9     3745.898948     10.940469       604.215117        2.587434   \n",
       "10    2085.652683      4.246603       460.848863        1.910426   \n",
       "11    3830.501880     15.893937       606.683108        3.475267   \n",
       "12    2096.253225      0.004640       433.815838        5.677770   \n",
       "13    3169.368937     14.668849       594.174452        2.735545   \n",
       "14    2140.779276      1.141463       453.459949        2.678942   \n",
       "15    3519.518125      5.917576       597.630370        1.367689   \n",
       "16    2127.041051      0.837467       448.245053        1.995626   \n",
       "17    3540.382144      4.488180       575.149153        0.853354   \n",
       "18    2085.702826      0.342291       448.762542        1.234084   \n",
       "19    2797.111483      3.232854       351.303936        0.091055   \n",
       "20    2027.558751      0.114148       367.692268        1.896880   \n",
       "21    2910.646857      5.999643       346.844988        1.177604   \n",
       "22    1800.047715      2.550900       255.973633        0.882170   \n",
       "23    2477.278483     14.709941       249.095248        2.074602   \n",
       "\n",
       "   param_bagging_fraction param_boosting_type param_feature_fraction  \\\n",
       "0                     0.6                gbdt                    0.7   \n",
       "1                     0.6                gbdt                    0.7   \n",
       "2                     0.6                gbdt                    0.7   \n",
       "3                     0.6                gbdt                    0.7   \n",
       "4                     0.6                gbdt                    0.7   \n",
       "5                     0.6                gbdt                    0.7   \n",
       "6                     0.6                gbdt                    0.7   \n",
       "7                     0.6                gbdt                    0.7   \n",
       "8                     0.6                gbdt                    0.7   \n",
       "9                     0.6                gbdt                    0.7   \n",
       "10                    0.6                gbdt                    0.7   \n",
       "11                    0.6                gbdt                    0.7   \n",
       "12                    0.6                gbdt                    0.7   \n",
       "13                    0.6                gbdt                    0.7   \n",
       "14                    0.6                gbdt                    0.7   \n",
       "15                    0.6                gbdt                    0.7   \n",
       "16                    0.6                gbdt                    0.7   \n",
       "17                    0.6                gbdt                    0.7   \n",
       "18                    0.6                gbdt                    0.7   \n",
       "19                    0.6                gbdt                    0.7   \n",
       "20                    0.6                gbdt                    0.7   \n",
       "21                    0.6                gbdt                    0.7   \n",
       "22                    0.6                gbdt                    0.7   \n",
       "23                    0.6                gbdt                    0.7   \n",
       "\n",
       "   param_lambda_l1 param_lambda_l2 param_learning_rate  ...  \\\n",
       "0                0               0                0.03  ...   \n",
       "1                0               0                0.03  ...   \n",
       "2                0               0                0.03  ...   \n",
       "3                0               0                0.03  ...   \n",
       "4                0               0                0.03  ...   \n",
       "5                0               0                0.03  ...   \n",
       "6                0             0.1                0.03  ...   \n",
       "7                0             0.1                0.03  ...   \n",
       "8                0             0.1                0.03  ...   \n",
       "9                0             0.1                0.03  ...   \n",
       "10               0             0.1                0.03  ...   \n",
       "11               0             0.1                0.03  ...   \n",
       "12             0.1               0                0.03  ...   \n",
       "13             0.1               0                0.03  ...   \n",
       "14             0.1               0                0.03  ...   \n",
       "15             0.1               0                0.03  ...   \n",
       "16             0.1               0                0.03  ...   \n",
       "17             0.1               0                0.03  ...   \n",
       "18             0.1             0.1                0.03  ...   \n",
       "19             0.1             0.1                0.03  ...   \n",
       "20             0.1             0.1                0.03  ...   \n",
       "21             0.1             0.1                0.03  ...   \n",
       "22             0.1             0.1                0.03  ...   \n",
       "23             0.1             0.1                0.03  ...   \n",
       "\n",
       "                                               params split0_test_score  \\\n",
       "0   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700552   \n",
       "1   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.711197   \n",
       "2   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700552   \n",
       "3   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.712538   \n",
       "4   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700552   \n",
       "5   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.712561   \n",
       "6   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.701223   \n",
       "7   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.710906   \n",
       "8   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.701223   \n",
       "9   {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.711532   \n",
       "10  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.701223   \n",
       "11  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.712270   \n",
       "12  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700888   \n",
       "13  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.712225   \n",
       "14  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700888   \n",
       "15  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.712248   \n",
       "16  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700888   \n",
       "17  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.711800   \n",
       "18  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700127   \n",
       "19  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.711085   \n",
       "20  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700127   \n",
       "21  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.712538   \n",
       "22  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.700127   \n",
       "23  {'bagging_fraction': 0.6, 'boosting_type': 'gb...          0.712762   \n",
       "\n",
       "   split1_test_score mean_test_score std_test_score rank_test_score  \\\n",
       "0           0.700836        0.700694       0.000142              22   \n",
       "1           0.709893        0.710545       0.000652              12   \n",
       "2           0.700836        0.700694       0.000142              22   \n",
       "3           0.710318        0.711428       0.001110               5   \n",
       "4           0.700836        0.700694       0.000142              22   \n",
       "5           0.710072        0.711316       0.001244               7   \n",
       "6           0.701776        0.701499       0.000276              13   \n",
       "7           0.710653        0.710780       0.000126              11   \n",
       "8           0.701776        0.701499       0.000276              13   \n",
       "9           0.710944        0.711238       0.000294               8   \n",
       "10          0.701776        0.701499       0.000276              13   \n",
       "11          0.710743        0.711506       0.000764               4   \n",
       "12          0.701887        0.701388       0.000500              16   \n",
       "13          0.709938        0.711082       0.001144              10   \n",
       "14          0.701887        0.701388       0.000500              16   \n",
       "15          0.710542        0.711395       0.000853               6   \n",
       "16          0.701887        0.701388       0.000500              16   \n",
       "17          0.711369        0.711585       0.000216               3   \n",
       "18          0.701552        0.700840       0.000712              19   \n",
       "19          0.711168        0.711126       0.000041               9   \n",
       "20          0.701552        0.700840       0.000712              19   \n",
       "21          0.711772        0.712155       0.000383               1   \n",
       "22          0.701552        0.700840       0.000712              19   \n",
       "23          0.711280        0.712021       0.000741               2   \n",
       "\n",
       "    split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "0             0.864574            0.863615          0.864094         0.000479  \n",
       "1             0.971242            0.970057          0.970650         0.000592  \n",
       "2             0.864574            0.863615          0.864094         0.000479  \n",
       "3             0.976408            0.974776          0.975592         0.000816  \n",
       "4             0.864574            0.863615          0.864094         0.000479  \n",
       "5             0.976676            0.975313          0.975994         0.000682  \n",
       "6             0.860682            0.859568          0.860125         0.000557  \n",
       "7             0.968782            0.967665          0.968223         0.000559  \n",
       "8             0.860682            0.859568          0.860125         0.000557  \n",
       "9             0.974440            0.972629          0.973534         0.000905  \n",
       "10            0.860682            0.859568          0.860125         0.000557  \n",
       "11            0.974149            0.972965          0.973557         0.000592  \n",
       "12            0.863098            0.861245          0.862171         0.000926  \n",
       "13            0.970415            0.968403          0.969409         0.001006  \n",
       "14            0.863098            0.861245          0.862171         0.000926  \n",
       "15            0.974753            0.973300          0.974026         0.000726  \n",
       "16            0.863098            0.861245          0.862171         0.000926  \n",
       "17            0.974686            0.973747          0.974216         0.000469  \n",
       "18            0.858290            0.857175          0.857732         0.000557  \n",
       "19            0.967575            0.966368          0.966971         0.000603  \n",
       "20            0.858290            0.857175          0.857732         0.000557  \n",
       "21            0.972472            0.971354          0.971913         0.000559  \n",
       "22            0.858290            0.857175          0.857732         0.000557  \n",
       "23            0.972830            0.971556          0.972193         0.000637  \n",
       "\n",
       "[24 rows x 25 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = clf.best_estimator_\n",
    "y_pred = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Accuracy = 0.733\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Test')\n",
    "print_stats(y_pred, y_test, X_test.columns, sep='-', sep_len=40, fig_size=(10,8))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Accuracy = 0.918\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_1 = bst.predict(X_train)\n",
    "print('train')\n",
    "print_stats(y_pred_1, y_train, X_train.columns, sep='-', sep_len=40, fig_size=(10,8))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LGBMModel.get_params of LGBMClassifier(bagging_fraction=0.6, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction=0.7,\n",
       "               importance_type='split', is_unbalance=True, lambda_l1=0,\n",
       "               lambda_l2=0, learning_rate=0.03, max_depth=20,\n",
       "               metric='multi_error', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=200,\n",
       "               n_jobs=-1,\n",
       "               num_class=<bound method In...n.nunique of 0            white blend\n",
       "1         portuguese red\n",
       "2             pinot gris\n",
       "3               riesling\n",
       "4             pinot noir\n",
       "               ...      \n",
       "111792          riesling\n",
       "111793        pinot noir\n",
       "111794     gewrztraminer\n",
       "111795        pinot gris\n",
       "111796     gewrztraminer\n",
       "Name: target, Length: 111797, dtype: object>,\n",
       "               num_leaves=50, objective='multiclass', random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, seed=42, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(lgbm.feature_importances_, index=X.columns)\n",
    "feat_imp.nlargest(30).plot(kind='barh', figsize=(8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "shap_values = shap.TreeExplainer(bst.booster_).shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the visualizer and draw the vectors\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "\n",
    "\n",
    "X_train = pd.get_dummies(X_train)\n",
    "plt.figure(figsize = [15,9])\n",
    "tsne = TSNEVisualizer()\n",
    "tsne.fit(X_train, y_train)\n",
    "tsne.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-5021a6e96b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNEVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/yellowbrick/text/tsne.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# Fit our internal transformer and transform the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_instances_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \"\"\"\n\u001b[1;32m    384\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    387\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mReduced\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mwill\u001b[0m \u001b[0malways\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdense\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m         X = check_array(X, accept_sparse=['csr', 'csc'],\n\u001b[0m\u001b[1;32m    162\u001b[0m                         ensure_min_features=2)\n\u001b[1;32m    163\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    578\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     56\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "aux = X.drop(['country', 'taster_name'], axis=1)\n",
    "\n",
    "tsne = TSNEVisualizer()\n",
    "tsne.fit(aux, y)\n",
    "tsne.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
